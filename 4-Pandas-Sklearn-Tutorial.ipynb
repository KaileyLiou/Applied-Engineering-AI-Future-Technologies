{"cells":[{"cell_type":"markdown","metadata":{"cell_id":"04c31aec0bd44d3390b0f0b12c7af728","deepnote_cell_type":"markdown"},"source":"# Introduction to Pandas and scikit-learn (sklearn)\nTutorial created by Divya with some content adapted from Tirendaz Academy\n\n## Overview of Pandas\nPandas is one of the most important libraries of Python. Pandas has data structures for data analysis. The most used of these are Series and DataFrame data structures. Series is one dimensional, that is, it consists of a column. Data frame is two-dimensional, i.e. it consists of rows and columns.\n\n## Overview of sklearn\nsklearn is a powerful Python library for **machine learning**. It has tools to help us build models that can make predictions based on data, such as predicting grades based on study hours or guessing someone’s favorite movie genre.","block_group":"49b266aad9ec41458d5d529b5323d996"},{"cell_type":"markdown","metadata":{"cell_id":"afe12364fd8f430dbbe90af4aab1fceb","deepnote_cell_type":"markdown"},"source":"More information at the Pandas web page: https://pandas.pydata.org/\n\nMore information at the scikit-learn web page: https://scikit-learn.org","block_group":"a7ff109964eb46b1b0ab7e7864c01e76"},{"cell_type":"markdown","metadata":{"cell_id":"74c0fecc4bfc4fbba8b8bb0046f0a29b","deepnote_cell_type":"markdown"},"source":"## Setting up\nTo get started, install Pandas with `pip install pandas`\nAnd install scikit-learn with `pip install scikit-learn`\nAnd let's import it as follows:","block_group":"eaa5dbc5624444df8cba85e616a0330b"},{"cell_type":"code","metadata":{"collapsed":false,"source_hash":"99204b21","execution_start":1763839690350,"execution_millis":817,"execution_context_id":"257866fe-2a6e-4b56-87d9-82b66555a8a2","cell_id":"bfb368d20ed64eed87006aa890620c39","deepnote_cell_type":"code"},"source":"import pandas as pd # pd is just a shorter way to call pandas functions\npd.__version__ # let's check the version\n\nimport sklearn","block_group":"b010b331bdce4294a5fa08200ba471a9","execution_count":1,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"cell_id":"bb0421d8f14b47d99303449a592f0bc5","deepnote_cell_type":"markdown"},"source":"### Why Use Pandas?\n1. Organized Data: With pandas, data is structured in a clear format called a DataFrame (think of it as a spreadsheet).\n2. Easy Data Analysis: It provides tools to explore and summarize data, like finding averages, sorting, or filtering out specific values.\n3. Data Cleaning: You can use pandas to fix, remove, or fill in missing data.\n4. Compatibility: Pandas works well with other Python libraries, especially ones for visualization like matplotlib, so you can easily plot and visualize data.\n\nIn short, pandas helps turn data into valuable insights, making data analysis easier, faster, and more efficient.","block_group":"46ca6c89bab84be48729fc3ee507ab95"},{"cell_type":"markdown","metadata":{"cell_id":"ebf646104f31472cb6b61c06cbfb5917","deepnote_cell_type":"markdown"},"source":"### Why Use sklearn?\n1. User-Friendly: It has simple functions to handle complex machine learning tasks, making it beginner-friendly.\n2. Variety of Models: sklearn includes many pre-built algorithms, like decision trees, linear regression, and clustering models, so we can experiment with different methods.\n3. Data Handling: It provides tools to split data, transform features, and evaluate model accuracy, all in one place.\n4. Interoperability: sklearn works well with other Python libraries like pandas and matplotlib, making it easy to visualize and process data.\n\nIn short, sklearn makes machine learning accessible, efficient, and enjoyable to explore and use!","block_group":"29507505bfc74711b2563967b59ea0cb"},{"cell_type":"markdown","metadata":{"cell_id":"2ea4cf51974b485783390ea22d681709","deepnote_cell_type":"markdown"},"source":"# Let's get into Pandas first!","block_group":"0f08105f63f5434bb6fd44035f55b03e"},{"cell_type":"markdown","metadata":{"cell_id":"0a6589202363421fa04dc4e3ceaffc75","deepnote_cell_type":"markdown"},"source":"## Creating A DataFrame","block_group":"9ae15b041096459aaf621bab15f26d82"},{"cell_type":"markdown","metadata":{"cell_id":"da32ca6a90be4c41bdafb234693d3647","deepnote_cell_type":"markdown"},"source":"What is a DataFrame?: A DataFrame is like a table with rows and columns.\n\nNow let's create a simple DataFrame with some random data as follows:","block_group":"85b1e737cf5246d9b7981d356966ce3c"},{"cell_type":"code","metadata":{"collapsed":false,"source_hash":"8c4c93f8","execution_start":1763839691232,"execution_millis":1,"execution_context_id":"257866fe-2a6e-4b56-87d9-82b66555a8a2","cell_id":"e5f173b161ec423f82b4d31e7d762c73","deepnote_cell_type":"code"},"source":"# say we have this data\ndata = {\n    'Name': ['Alice', 'Bob', 'Charlie'],\n    'Age': [17, 18, 16],\n    'Grade': ['A', 'B', 'A']\n}\n\n# now let's turn it into a DataFrame with the following line\nschool_df = pd.DataFrame(data)\nprint(school_df)","block_group":"302aed1b88ef4f9ba950d29b902eb28c","execution_count":2,"outputs":[{"name":"stdout","text":"      Name  Age Grade\n0    Alice   17     A\n1      Bob   18     B\n2  Charlie   16     A\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/d47f4ec5-8ef3-4e4e-bf1a-ba207acb0aee","content_dependencies":null},{"cell_type":"markdown","metadata":{"cell_id":"c88562b9c3954ce5931dc052e4200b41","deepnote_cell_type":"markdown"},"source":"Notice how each column is like a key in a dictionary, and each individual list represents values for that column","block_group":"5fe979ee1fd34c87b2db252c48659dde"},{"cell_type":"markdown","metadata":{"cell_id":"b1a983d06c3548dfa559b3c7263d1b95","deepnote_cell_type":"markdown"},"source":"## Basic DataFrame Operations\n\n- `df.head()` - Shows the first few rows.\n- `df.tail()` - Shows the last few rows.\n- `df.info()` - Shows information about the DataFrame.\n- `df.shape` - Shows the number of rows and columns.\n- `df.dtypes` - Shows the data types of each column.\n- `df.describe()` - Shows summary statistics for each column.\n- `df.columns` - Shows the column names.\n\nLet's see these in action now:","block_group":"c9c66611522a4dc7ac92771e5d04305c"},{"cell_type":"code","metadata":{"source_hash":"7bd8fb87","execution_start":1763839691292,"execution_millis":1,"execution_context_id":"257866fe-2a6e-4b56-87d9-82b66555a8a2","cell_id":"6392d1e5e1094c5e9c2b8381d5b01685","deepnote_cell_type":"code"},"source":"school_df.head()\n\n# school_df.tail() \n\n# This would show us the same information as school_df.head() \n# since we only have 3 rows in our DataFrame right now","block_group":"9ba3f8bd5a5342b280e832778884897c","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"application/vnd.deepnote.dataframe.v3+json":{"column_count":3,"columns":[{"name":"Name","dtype":"object","stats":{"unique_count":3,"nan_count":0,"min":null,"max":null,"histogram":null,"categories":[{"name":"Alice","count":1},{"name":"Bob","count":1},{"name":"Charlie","count":1}]}},{"name":"Age","dtype":"int64","stats":{"unique_count":3,"nan_count":0,"min":"16","max":"18","histogram":[{"bin_start":16,"bin_end":16.2,"count":1},{"bin_start":16.2,"bin_end":16.4,"count":0},{"bin_start":16.4,"bin_end":16.6,"count":0},{"bin_start":16.6,"bin_end":16.8,"count":0},{"bin_start":16.8,"bin_end":17,"count":0},{"bin_start":17,"bin_end":17.2,"count":1},{"bin_start":17.2,"bin_end":17.4,"count":0},{"bin_start":17.4,"bin_end":17.6,"count":0},{"bin_start":17.6,"bin_end":17.8,"count":0},{"bin_start":17.8,"bin_end":18,"count":1}],"categories":null}},{"name":"Grade","dtype":"object","stats":{"unique_count":2,"nan_count":0,"min":null,"max":null,"histogram":null,"categories":[{"name":"A","count":2},{"name":"B","count":1}]}},{"name":"_deepnote_index_column","dtype":"int64"}],"row_count":3,"preview_row_count":3,"rows":[{"Name":"Alice","Age":17,"Grade":"A","_deepnote_index_column":0},{"Name":"Bob","Age":18,"Grade":"B","_deepnote_index_column":1},{"Name":"Charlie","Age":16,"Grade":"A","_deepnote_index_column":2}],"type":"dataframe"},"text/plain":"      Name  Age Grade\n0    Alice   17     A\n1      Bob   18     B\n2  Charlie   16     A","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Name</th>\n      <th>Age</th>\n      <th>Grade</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Alice</td>\n      <td>17</td>\n      <td>A</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Bob</td>\n      <td>18</td>\n      <td>B</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Charlie</td>\n      <td>16</td>\n      <td>A</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{"table_state_spec":null}}],"outputs_reference":"s3:deepnote-cell-outputs-production/af76c5c2-8cfe-4b18-8187-c1078445952c","content_dependencies":null},{"cell_type":"markdown","metadata":{"cell_id":"39a8ea76fb264ce3ba84ec01cae9996b","deepnote_cell_type":"markdown"},"source":"Note that we can also specify the number of rows to show:","block_group":"727e63ec358140bfb61f6c3d3dd2c35c"},{"cell_type":"code","metadata":{"source_hash":"c763aa12","execution_start":1763839691350,"execution_millis":1,"execution_context_id":"257866fe-2a6e-4b56-87d9-82b66555a8a2","cell_id":"00fbf22c18414fe386e9a5ba97d755b3","deepnote_cell_type":"code"},"source":"school_df.head(2)","block_group":"d08ddb2f16634e26886bf89d6038ee7b","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"application/vnd.deepnote.dataframe.v3+json":{"column_count":3,"columns":[{"name":"Name","dtype":"object","stats":{"unique_count":2,"nan_count":0,"min":null,"max":null,"histogram":null,"categories":[{"name":"Alice","count":1},{"name":"Bob","count":1}]}},{"name":"Age","dtype":"int64","stats":{"unique_count":2,"nan_count":0,"min":"17","max":"18","histogram":[{"bin_start":17,"bin_end":17.1,"count":1},{"bin_start":17.1,"bin_end":17.2,"count":0},{"bin_start":17.2,"bin_end":17.3,"count":0},{"bin_start":17.3,"bin_end":17.4,"count":0},{"bin_start":17.4,"bin_end":17.5,"count":0},{"bin_start":17.5,"bin_end":17.6,"count":0},{"bin_start":17.6,"bin_end":17.7,"count":0},{"bin_start":17.7,"bin_end":17.8,"count":0},{"bin_start":17.8,"bin_end":17.9,"count":0},{"bin_start":17.9,"bin_end":18,"count":1}],"categories":null}},{"name":"Grade","dtype":"object","stats":{"unique_count":2,"nan_count":0,"min":null,"max":null,"histogram":null,"categories":[{"name":"A","count":1},{"name":"B","count":1}]}},{"name":"_deepnote_index_column","dtype":"int64"}],"row_count":2,"preview_row_count":2,"rows":[{"Name":"Alice","Age":17,"Grade":"A","_deepnote_index_column":0},{"Name":"Bob","Age":18,"Grade":"B","_deepnote_index_column":1}],"type":"dataframe"},"text/plain":"    Name  Age Grade\n0  Alice   17     A\n1    Bob   18     B","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Name</th>\n      <th>Age</th>\n      <th>Grade</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Alice</td>\n      <td>17</td>\n      <td>A</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Bob</td>\n      <td>18</td>\n      <td>B</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{"table_state_spec":null}}],"outputs_reference":"s3:deepnote-cell-outputs-production/c44dc56d-190c-4401-8174-8773664c5faa","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"9fe85e8c","execution_start":1763839691402,"execution_millis":0,"execution_context_id":"257866fe-2a6e-4b56-87d9-82b66555a8a2","cell_id":"fb5f09c6ded14e28a4abd07970595465","deepnote_cell_type":"code"},"source":"print(\"Info: \", school_df.info())","block_group":"698c0f6f6e60444bb8f3e8ae4af327fc","execution_count":5,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 3 entries, 0 to 2\nData columns (total 3 columns):\n #   Column  Non-Null Count  Dtype \n---  ------  --------------  ----- \n 0   Name    3 non-null      object\n 1   Age     3 non-null      int64 \n 2   Grade   3 non-null      object\ndtypes: int64(1), object(2)\nmemory usage: 200.0+ bytes\nInfo:  None\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/34562236-990d-4dac-bc49-d492f6cb6b8d","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"408c45f9","execution_start":1763839691452,"execution_millis":1,"execution_context_id":"257866fe-2a6e-4b56-87d9-82b66555a8a2","cell_id":"86be8ec979a041419f9a4e0dcf44df30","deepnote_cell_type":"code"},"source":"print(\"Shape: \", school_df.shape)\n\nprint(\"Data types:\\n \", school_df.dtypes)\n\nprint(\"Summary statistics: \\n\", school_df.describe()) #\\n is a new line\n\nprint(\"Column names: \", school_df.columns)","block_group":"53ebdaa66d44446a96585057a4ed92d9","execution_count":6,"outputs":[{"name":"stdout","text":"Shape:  (3, 3)\nData types:\n  Name     object\nAge       int64\nGrade    object\ndtype: object\nSummary statistics: \n         Age\ncount   3.0\nmean   17.0\nstd     1.0\nmin    16.0\n25%    16.5\n50%    17.0\n75%    17.5\nmax    18.0\nColumn names:  Index(['Name', 'Age', 'Grade'], dtype='object')\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/c0af5c7b-feb9-4d21-b304-cfdd780b6c9b","content_dependencies":null},{"cell_type":"markdown","metadata":{"cell_id":"055ebb29ebd746e590a8914114b79e20","deepnote_cell_type":"markdown"},"source":"### Accessing Columns\n\n- `df.column_name` OR `df[\"column_name\"]` - Accesses a column by name.","block_group":"2e6987debc79467881758762ab958db1"},{"cell_type":"code","metadata":{"source_hash":"49d4d944","execution_start":1763839691502,"execution_millis":1,"execution_context_id":"257866fe-2a6e-4b56-87d9-82b66555a8a2","cell_id":"af3e9bd053c34343b86baafeabe30a40","deepnote_cell_type":"code"},"source":"print(school_df.Name)\n\nprint(\"\\n results in the same output as \\n\")\n\nprint(school_df[\"Name\"])","block_group":"b43ebf8824b24b8cae0c47db95d8eaba","execution_count":7,"outputs":[{"name":"stdout","text":"0      Alice\n1        Bob\n2    Charlie\nName: Name, dtype: object\n\n results in the same output as \n\n0      Alice\n1        Bob\n2    Charlie\nName: Name, dtype: object\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/c959b587-802b-4feb-b207-614d53cc97d8","content_dependencies":null},{"cell_type":"markdown","metadata":{"cell_id":"c820ae2e666a4a6ebd98701ced27201e","deepnote_cell_type":"markdown"},"source":"### What if I want to access multiple columns?\n\nWe can do that too!","block_group":"a4cbaa08839047998a4764d43e9dbfae"},{"cell_type":"code","metadata":{"source_hash":"6dcf84ae","execution_start":1763839691562,"execution_millis":1,"execution_context_id":"257866fe-2a6e-4b56-87d9-82b66555a8a2","cell_id":"8e7c6b73a94044b6a170253624f21769","deepnote_cell_type":"code"},"source":"school_df[[\"Name\", \"Age\"]] # notice how the output matches the order of which columns we asked for first","block_group":"ed5735ec280949c2ba7a3067dee9fcf4","execution_count":8,"outputs":[{"output_type":"execute_result","execution_count":8,"data":{"application/vnd.deepnote.dataframe.v3+json":{"column_count":2,"columns":[{"name":"Name","dtype":"object","stats":{"unique_count":3,"nan_count":0,"min":null,"max":null,"histogram":null,"categories":[{"name":"Alice","count":1},{"name":"Bob","count":1},{"name":"Charlie","count":1}]}},{"name":"Age","dtype":"int64","stats":{"unique_count":3,"nan_count":0,"min":"16","max":"18","histogram":[{"bin_start":16,"bin_end":16.2,"count":1},{"bin_start":16.2,"bin_end":16.4,"count":0},{"bin_start":16.4,"bin_end":16.6,"count":0},{"bin_start":16.6,"bin_end":16.8,"count":0},{"bin_start":16.8,"bin_end":17,"count":0},{"bin_start":17,"bin_end":17.2,"count":1},{"bin_start":17.2,"bin_end":17.4,"count":0},{"bin_start":17.4,"bin_end":17.6,"count":0},{"bin_start":17.6,"bin_end":17.8,"count":0},{"bin_start":17.8,"bin_end":18,"count":1}],"categories":null}},{"name":"_deepnote_index_column","dtype":"int64"}],"row_count":3,"preview_row_count":3,"rows":[{"Name":"Alice","Age":17,"_deepnote_index_column":0},{"Name":"Bob","Age":18,"_deepnote_index_column":1},{"Name":"Charlie","Age":16,"_deepnote_index_column":2}],"type":"dataframe"},"text/plain":"      Name  Age\n0    Alice   17\n1      Bob   18\n2  Charlie   16","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Name</th>\n      <th>Age</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Alice</td>\n      <td>17</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Bob</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Charlie</td>\n      <td>16</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{"table_state_spec":null}}],"outputs_reference":"s3:deepnote-cell-outputs-production/568b9670-4950-4dd0-9c31-a8af1be2bef2","content_dependencies":null},{"cell_type":"markdown","metadata":{"cell_id":"2792111dc1ef46cbb5175692dc92848c","deepnote_cell_type":"markdown"},"source":"## Filtering Data\n\nLet's say we only want to look at students who are older than 16.","block_group":"b815316730884bf9a9165d668224abec"},{"cell_type":"code","metadata":{"source_hash":"8b7b27dd","execution_start":1763839691612,"execution_millis":0,"execution_context_id":"257866fe-2a6e-4b56-87d9-82b66555a8a2","cell_id":"9c0653ac941d45a6ba9c7f5e6de4506c","deepnote_cell_type":"code"},"source":"print(school_df[school_df['Age'] > 16])  # Show students older than 16","block_group":"b54c9a94f5bb4d9888f4a7f79fb3cba5","execution_count":9,"outputs":[{"name":"stdout","text":"    Name  Age Grade\n0  Alice   17     A\n1    Bob   18     B\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/27c6fa96-587a-4bcc-a639-9bcbb69d1c45","content_dependencies":null},{"cell_type":"markdown","metadata":{"cell_id":"5cf2569f93244bf1954037b32f4a7657","deepnote_cell_type":"markdown"},"source":"What about students who are older than 16 AND who have an A?","block_group":"a54e627df4e64b2e8faa06f45f863d04"},{"cell_type":"code","metadata":{"source_hash":"c3bdec6b","execution_start":1763839691662,"execution_millis":0,"execution_context_id":"257866fe-2a6e-4b56-87d9-82b66555a8a2","cell_id":"cc80d4c086de4ec9910b6f692b90a74d","deepnote_cell_type":"code"},"source":"print(school_df[(school_df['Age'] > 16) & (school_df['Grade'] == 'A')])","block_group":"d9432893357e48ceae9fb119fa4a441e","execution_count":10,"outputs":[{"name":"stdout","text":"    Name  Age Grade\n0  Alice   17     A\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/26b67bd7-1db7-4a60-b5b8-3980a12bfb09","content_dependencies":null},{"cell_type":"markdown","metadata":{"cell_id":"175ca49771af41438092e71146d6be30","deepnote_cell_type":"markdown"},"source":"## Selecting Data with loc and iloc\n\nWhat is the difference between loc and iloc?\n\n- `df.loc[]` - Selects rows and columns by label.\n- `df.iloc[]` - Selects rows and columns by integer position.\n\nFor example:","block_group":"49c3bdd6ab10444bada1129c9cc8eb94"},{"cell_type":"code","metadata":{"source_hash":"b8f42a8","execution_start":1763839691712,"execution_millis":0,"execution_context_id":"257866fe-2a6e-4b56-87d9-82b66555a8a2","cell_id":"cda6bc119d4c477194f57a831f3862f0","deepnote_cell_type":"code"},"source":"# using loc\nprint(\"Using loc:\")\nprint(school_df.loc[0, 'Name'])\nprint(school_df.loc[0:2, 'Name'])\n\n# using iloc\nprint(\"\\nUsing iloc:\")\nprint(school_df.iloc[0, 0]) # the Name column is the 0th row\nprint(school_df.iloc[0:3, 0]) ","block_group":"50d7f840a9e944cabe8706a941653e1e","execution_count":11,"outputs":[{"name":"stdout","text":"Using loc:\nAlice\n0      Alice\n1        Bob\n2    Charlie\nName: Name, dtype: object\n\nUsing iloc:\nAlice\n0      Alice\n1        Bob\n2    Charlie\nName: Name, dtype: object\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/d2694252-4a71-4b8f-98e9-3316479df5fa","content_dependencies":null},{"cell_type":"markdown","metadata":{"cell_id":"07cceb603da74d3caf7cdb1880037a1b","deepnote_cell_type":"markdown"},"source":"## Adding and Modifying Columns\n\nLet's add a column and base it's value off of another column.","block_group":"01949a5725ea41a2b3bbe4aeb7b91cd7"},{"cell_type":"code","metadata":{"source_hash":"24181963","execution_start":1763839692122,"execution_millis":1,"execution_context_id":"257866fe-2a6e-4b56-87d9-82b66555a8a2","cell_id":"25ab1bdf1df6432e8806391d17e29fa5","deepnote_cell_type":"code"},"source":"# let's add a new column called \"Passed\"\n# we want this column to be a boolean\n# and we wan to base it off of the \"Grade\" column\n\nschool_df['Passed'] = school_df['Grade'] == 'A'\nprint(school_df)","block_group":"a30d01d0e40345f08c05a2eee4264bc2","execution_count":12,"outputs":[{"name":"stdout","text":"      Name  Age Grade  Passed\n0    Alice   17     A    True\n1      Bob   18     B   False\n2  Charlie   16     A    True\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/3ddbc852-ff79-4b48-bc44-4baae35c3828","content_dependencies":null},{"cell_type":"markdown","metadata":{"cell_id":"b9300503c2e74364a8f73b6abd0d76c9","deepnote_cell_type":"markdown"},"source":"Now let's see how to modify an existing column.\nLet's add 1 to the \"Age\" column","block_group":"9fe3c19b11224703b4fd5795ebafde36"},{"cell_type":"code","metadata":{"source_hash":"cefe2db8","execution_start":1763839692182,"execution_millis":1,"execution_context_id":"257866fe-2a6e-4b56-87d9-82b66555a8a2","cell_id":"f7ea11f72ba64a428cc2f457854bb1c8","deepnote_cell_type":"code"},"source":"print(\"Original:\")\nprint(school_df)\n\nprint(\"\\nModified:\")\nschool_df['Age'] = school_df['Age'] + 1\nprint(school_df)","block_group":"695667e12fc24033b251ef09dc6d6c9f","execution_count":13,"outputs":[{"name":"stdout","text":"Original:\n      Name  Age Grade  Passed\n0    Alice   17     A    True\n1      Bob   18     B   False\n2  Charlie   16     A    True\n\nModified:\n      Name  Age Grade  Passed\n0    Alice   18     A    True\n1      Bob   19     B   False\n2  Charlie   17     A    True\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/e6306fd3-bab8-4442-8f68-97ffcdd0e507","content_dependencies":null},{"cell_type":"markdown","metadata":{"cell_id":"1e712a7e6bef43d48434f76d4c5e1590","deepnote_cell_type":"markdown"},"source":"## Basic Data Analysis\n\nLet's calcualte a few basic statistics with this data:","block_group":"477036e9c8794084928d1aca721ad631"},{"cell_type":"code","metadata":{"source_hash":"86bfce40","execution_start":1763839692246,"execution_millis":0,"execution_context_id":"257866fe-2a6e-4b56-87d9-82b66555a8a2","cell_id":"526579f3b0484381925ed1df6ae904a2","deepnote_cell_type":"code"},"source":"average_age = school_df['Age'].mean() # notice how we are using .mean()\nprint(f\"Average Age: {average_age}\") # different way to use print()\n\nmost_common_grade = school_df['Grade'].value_counts().idxmax()\nprint(f\"\\nMost common grade: {most_common_grade}\")\n\nyoungest_student = school_df[school_df['Age'] == school_df['Age'].min()]\nprint(f\"\\nYoungest Student:\\n {youngest_student}\")","block_group":"4ed8a169dd8c4ab0aacd687cc845c1f1","execution_count":14,"outputs":[{"name":"stdout","text":"Average Age: 18.0\n\nMost common grade: A\n\nYoungest Student:\n       Name  Age Grade  Passed\n2  Charlie   17     A    True\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/c87815aa-55bf-4a12-adc0-f4db04be8fcf","content_dependencies":null},{"cell_type":"markdown","metadata":{"cell_id":"97066b9b888d4781bda24bed75b2fcae","deepnote_cell_type":"markdown"},"source":"## Missing Data\n\n- `df.isnull()` - Returns a DataFrame of all missing values\n- `df.notnull()` - Returns a DataFrame of all non-missing values\n- `df.fillna()` - Fills missing values with a specified value\n- `df.dropna()` - Drops rows with missing values\n\nLet's modify our data to include missing values:","block_group":"18d3f5a7d8424c83bf91a70b0fac1330"},{"cell_type":"code","metadata":{"source_hash":"76906c64","execution_start":1763839692312,"execution_millis":0,"execution_context_id":"257866fe-2a6e-4b56-87d9-82b66555a8a2","cell_id":"89cb3e275b6d4778b9f156f6a4ed485e","deepnote_cell_type":"code"},"source":"# let's create a new student with missing data\nschool_df.loc[3] = ['David', 16, 'C', None]\nprint(school_df)\n\n# now let's see if we can fill in the missing data\n# let's fill in the missing value with the mode of the Passed column\n\nmost_common_passing_status = school_df['Passed'].value_counts().idxmax()\nschool_df['Passed'] = school_df['Passed'].fillna(most_common_passing_status)\nprint(\"\\n Modified:\\n\", school_df)","block_group":"e37ff9f723f34c37a367acffe01dcf01","execution_count":15,"outputs":[{"name":"stdout","text":"      Name  Age Grade Passed\n0    Alice   18     A   True\n1      Bob   19     B  False\n2  Charlie   17     A   True\n3    David   16     C   None\n\n Modified:\n       Name  Age Grade  Passed\n0    Alice   18     A    True\n1      Bob   19     B   False\n2  Charlie   17     A    True\n3    David   16     C    True\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/e9e2097c-cb9b-482d-8fea-45113241fc2b","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"94cfed6","execution_start":1763839692372,"execution_millis":0,"execution_context_id":"257866fe-2a6e-4b56-87d9-82b66555a8a2","cell_id":"01f89e0a77c6427c830356eba2bfb0ed","deepnote_cell_type":"code"},"source":"# but that's not a good representation of our data\n# so let's just drop the row with missing data\n\n# to demonstate this example, let's set David's passing status back to None\nschool_df.loc[3, 'Passed'] = None\nprint(\"\\n Current DF with David's missing data:\\n\", school_df)\nschool_df = school_df.dropna()\nprint(\"\\n Modified Again:\\n\", school_df)","block_group":"94cac8f870b840c8b23a991c3aa4b993","execution_count":16,"outputs":[{"name":"stdout","text":"\n Current DF with David's missing data:\n       Name  Age Grade Passed\n0    Alice   18     A   True\n1      Bob   19     B  False\n2  Charlie   17     A   True\n3    David   16     C    NaN\n\n Modified Again:\n       Name  Age Grade Passed\n0    Alice   18     A   True\n1      Bob   19     B  False\n2  Charlie   17     A   True\n/tmp/ipykernel_460/3766917026.py:5: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n  school_df.loc[3, 'Passed'] = None\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/a19e97cd-f512-42ac-ad9f-1183c73ca154","content_dependencies":null},{"cell_type":"markdown","metadata":{"cell_id":"43cc905eea2b4a1798e70e4ef3a3064c","deepnote_cell_type":"markdown"},"source":"## Saving and Loading Data\n\nWe can easily save our DataFrame as a csv file / load csv files with pandas.","block_group":"da332abf2c7a4df4a191104af76edf1d"},{"cell_type":"code","metadata":{"source_hash":"3d459c40","execution_start":1763839692422,"execution_millis":167,"execution_context_id":"257866fe-2a6e-4b56-87d9-82b66555a8a2","cell_id":"b7b9dad815e248df920671f9ca65220e","deepnote_cell_type":"code"},"source":"# save the DataFrame to a csv file\nschool_df.to_csv('school.csv', index=False) # index = False will not save the index","block_group":"eb29d803a07f49608402f3bf49066276","execution_count":17,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"cell_id":"a3a8cab232c645b7ad47c643a6d46393","deepnote_cell_type":"markdown"},"source":"Now let's load this data into a new variable:","block_group":"ac372a81f59345b18da6f00a41b6b92d"},{"cell_type":"code","metadata":{"source_hash":"e3efac9e","execution_start":1763839692642,"execution_millis":396,"execution_context_id":"257866fe-2a6e-4b56-87d9-82b66555a8a2","cell_id":"197c6c6a0d5d4da7830832c48c9bdb75","deepnote_cell_type":"code"},"source":"# The error indicates that the file 'sp500_companies.csv' does not exist in the current directory.\n# To fix this, we should use the available 'school.csv' file instead.\n\n# Load the existing 'school.csv' file\nnew_df = pd.read_csv('school.csv')\n\n# Print the columns to understand the structure\nprint(new_df.columns.tolist())\nprint(new_df)\n\n# Since 'school.csv' does not have 'Symbol' and 'Shortname' columns,\n# we need to adjust the code to work with the available columns.\n\n# Let's assume we want to work with 'Name' and 'Grade' columns\nX = new_df['Name']\ny = new_df['Grade']\n\nprint(X)\nprint(y)","block_group":"97490974d00948498cb444f3e2a4e9e4","execution_count":18,"outputs":[{"name":"stdout","text":"['Name', 'Age', 'Grade', 'Passed']\n      Name  Age Grade  Passed\n0    Alice   18     A    True\n1      Bob   19     B   False\n2  Charlie   17     A    True\n0      Alice\n1        Bob\n2    Charlie\nName: Name, dtype: object\n0    A\n1    B\n2    A\nName: Grade, dtype: object\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/d6cb5230-4afe-4982-bbdc-510760cd32bc","content_dependencies":null},{"cell_type":"markdown","metadata":{"cell_id":"51643886f60d44309031ea8c162089fb","deepnote_cell_type":"markdown"},"source":"# Now let's get into sklearn!\n\nsklearn is a very powerful machine learning library and I'd say it's easiest to learn through a demonstration:","block_group":"a6325b93425d4f129f000d7a028e79f8"},{"cell_type":"markdown","metadata":{"cell_id":"fab6cfd98a5b47f09ca34de002765f18","deepnote_cell_type":"markdown"},"source":"## Load in a dataset\nsklearn has a lot of built-in datasets that make it really easy to get started\n\nLet's load in the Iris dataset:\n\nThis dataset contains measurements of 150 flowers, with each flower being one of three species: Setosa, Versicolor, or Virginica.","block_group":"1d8d732eb5ba4671bb9880a9a2f8eca2"},{"cell_type":"code","metadata":{"source_hash":"a8235657","execution_start":1763839693092,"execution_millis":18,"execution_context_id":"257866fe-2a6e-4b56-87d9-82b66555a8a2","cell_id":"dde38a63f43e440f816f194625398b35","deepnote_cell_type":"code"},"source":"from sklearn.datasets import load_iris # loading in a built-in dataset from sklearn library\n\niris = load_iris()\nprint(iris.DESCR)  # Description of the dataset\n\n#print(iris)","block_group":"16e67b0ae73644c3b90bf7fefe726d7c","execution_count":19,"outputs":[{"name":"stdout","text":".. _iris_dataset:\n\nIris plants dataset\n--------------------\n\n**Data Set Characteristics:**\n\n    :Number of Instances: 150 (50 in each of three classes)\n    :Number of Attributes: 4 numeric, predictive attributes and the class\n    :Attribute Information:\n        - sepal length in cm\n        - sepal width in cm\n        - petal length in cm\n        - petal width in cm\n        - class:\n                - Iris-Setosa\n                - Iris-Versicolour\n                - Iris-Virginica\n                \n    :Summary Statistics:\n\n    ============== ==== ==== ======= ===== ====================\n                    Min  Max   Mean    SD   Class Correlation\n    ============== ==== ==== ======= ===== ====================\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n    ============== ==== ==== ======= ===== ====================\n\n    :Missing Attribute Values: None\n    :Class Distribution: 33.3% for each of 3 classes.\n    :Creator: R.A. Fisher\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n    :Date: July, 1988\n\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\nfrom Fisher's paper. Note that it's the same as in R, but not as in the UCI\nMachine Learning Repository, which has two wrong data points.\n\nThis is perhaps the best known database to be found in the\npattern recognition literature.  Fisher's paper is a classic in the field and\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\ndata set contains 3 classes of 50 instances each, where each class refers to a\ntype of iris plant.  One class is linearly separable from the other 2; the\nlatter are NOT linearly separable from each other.\n\n.. topic:: References\n\n   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n     Mathematical Statistics\" (John Wiley, NY, 1950).\n   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n     Structure and Classification Rule for Recognition in Partially Exposed\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n     on Information Theory, May 1972, 431-433.\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n     conceptual clustering system finds 3 classes in the data.\n   - Many, many more ...\n","output_type":"stream"}],"outputs_reference":"s3:deepnote-cell-outputs-production/cd1fadab-f024-4ec3-b862-4c03c5a76183","content_dependencies":null},{"cell_type":"markdown","metadata":{"cell_id":"ae33a638933544fcab5a80925b3b6d31","deepnote_cell_type":"markdown"},"source":"## Understanding the Data\n\nLet's take a look at the data:\n\nWhat are the features? What are the labels?\n\nRemember: the features are (usually) the columns of the dataset. ","block_group":"53ca44eb26e04c5686987eefe89e799d"},{"cell_type":"code","metadata":{"source_hash":"2ce84cdf","execution_start":1763839693172,"execution_millis":1,"execution_context_id":"257866fe-2a6e-4b56-87d9-82b66555a8a2","cell_id":"07df25379dce4f3db33104cdbb92c960","deepnote_cell_type":"code"},"source":"X = iris.data\ny = iris.target\n\nfeatures_df = pd.DataFrame(X, columns=iris.feature_names)\nprint(\"Features DataFrame:\\n\", features_df)\n\nlabels_df = pd.DataFrame(y, columns=['Species'])\nprint(\"\\nLabels DataFrame:\\n\", labels_df)\n\n# HEY! We're using pandas here!","block_group":"22963f56d2e548b78e8bcca0fc88b456","execution_count":20,"outputs":[{"name":"stdout","text":"Features DataFrame:\n      sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n0                  5.1               3.5                1.4               0.2\n1                  4.9               3.0                1.4               0.2\n2                  4.7               3.2                1.3               0.2\n3                  4.6               3.1                1.5               0.2\n4                  5.0               3.6                1.4               0.2\n..                 ...               ...                ...               ...\n145                6.7               3.0                5.2               2.3\n146                6.3               2.5                5.0               1.9\n147                6.5               3.0                5.2               2.0\n148                6.2               3.4                5.4               2.3\n149                5.9               3.0                5.1               1.8\n\n[150 rows x 4 columns]\n\nLabels DataFrame:\n      Species\n0          0\n1          0\n2          0\n3          0\n4          0\n..       ...\n145        2\n146        2\n147        2\n148        2\n149        2\n\n[150 rows x 1 columns]\n","output_type":"stream"}],"outputs_reference":"s3:deepnote-cell-outputs-production/46d5593e-025d-49b5-bb65-c516f50015ee","content_dependencies":null},{"cell_type":"markdown","metadata":{"cell_id":"7f9d77850cbd45cd9b56bc211aadc655","deepnote_cell_type":"markdown"},"source":"And now let's load the features into a variable called X and the labels into a variable called y:","block_group":"d32fca01838c4defb62a97974fa4c88a"},{"cell_type":"code","metadata":{"source_hash":"8f6520e8","execution_start":1763839693222,"execution_millis":0,"execution_context_id":"257866fe-2a6e-4b56-87d9-82b66555a8a2","cell_id":"88d44382a30049869266856a5130050a","deepnote_cell_type":"code"},"source":"X = iris.data      # Input data (features)\ny = iris.target    # Output labels (species)\n\nprint(\"X shape:\", X.shape, \"\\ny shape:\", y.shape)","block_group":"7b13daa252a44665b1ccee48fa1d3f23","execution_count":21,"outputs":[{"name":"stdout","text":"X shape: (150, 4) \ny shape: (150,)\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/70448542-4300-488d-9bb6-b433e4394479","content_dependencies":null},{"cell_type":"markdown","metadata":{"cell_id":"2af48db8fa8a492bb9dc0f9e4229939f","deepnote_cell_type":"markdown"},"source":"## Splitting Data for Training and Testing\n\nWhy is this important?\n\n- Training data is used to train the machine learning model\n- Testing data is used to test the accuracy of the machine learning model\n\nIn other words:\nBy training the model on one set of data and testing it on another, we can get a better idea of how well the model will perform in the real world. This split prevents the model from simply \"memorizing\" the data, helping it generalize better to new cases.","block_group":"628632d29ef9490db175c02101dfb5c5"},{"cell_type":"code","metadata":{"source_hash":"6936ca20","execution_start":1763839693282,"execution_millis":1,"execution_context_id":"257866fe-2a6e-4b56-87d9-82b66555a8a2","cell_id":"fe484ba5d9cf43ffbe0d6575efb10e24","deepnote_cell_type":"code"},"source":"# let's split our data\n\nfrom sklearn.model_selection import train_test_split # import train_test_split function\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# train_test_split takes in 4 arguments: X, y, test_size, random_state\n# the first 2 represent the data we want to split (our features and labels)\n# test_size = 0.2 means 20% of the data will be used for testing\n# random_state = 42 means we will use the same random split every time we run the code\n\n# train_test_split returns 4 variables:\n# X_train, X_test, y_train, y_test\n\n# let's print out the shape of our split data\nprint(\"X_train shape:\", X_train.shape, \"\\nX_test shape:\", X_test.shape, \"\\ny_train shape:\", y_train.shape, \"\\ny_test shape:\", y_test.shape)","block_group":"e54f0ade006b439481c798f195ee6070","execution_count":22,"outputs":[{"name":"stdout","text":"X_train shape: (120, 4) \nX_test shape: (30, 4) \ny_train shape: (120,) \ny_test shape: (30,)\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/963cda26-a609-477d-9672-7c63d40eedb9","content_dependencies":null},{"cell_type":"markdown","metadata":{"cell_id":"167555b4a4b543c8a13fa44fec15e782","deepnote_cell_type":"markdown"},"source":"## Creating a Simple Model\n\nLet's use a logistic regression model to make a prediction (i.e. classify the data into categories).\n\n(Why logistic regression?\nThis dataset is famous for how we can use a logistic regression model to classify data very well!)","block_group":"13a6d57ba3354cedb002da9ce54e19b8"},{"cell_type":"code","metadata":{"source_hash":"821c110c","execution_start":1763839693332,"execution_millis":9,"execution_context_id":"257866fe-2a6e-4b56-87d9-82b66555a8a2","cell_id":"2bf4cdf77f294948921292473f3581ad","deepnote_cell_type":"code"},"source":"from sklearn.linear_model import LogisticRegression # import LogisticRegression function\n\n# create the model\nmodel = LogisticRegression(max_iter=5) # max_iter is the number of iterations the model will run for\n\n# NOTE: 5 is WAYYY too low,\n# but I wanted to use it to demonstrate how we can later change this and see what happens\n\n# train the model\nmodel.fit(X_train, y_train)","block_group":"2ce539488c654cb882d7229a9f6593da","execution_count":23,"outputs":[{"name":"stderr","text":"/root/venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n","output_type":"stream"},{"output_type":"execute_result","execution_count":23,"data":{"text/plain":"LogisticRegression(max_iter=5)","text/html":"<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=5)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=5)</pre></div></div></div></div></div>"},"metadata":{}}],"outputs_reference":"s3:deepnote-cell-outputs-production/3abe3bab-73c5-4bc9-a4cf-db0c526c1362","content_dependencies":null},{"cell_type":"markdown","metadata":{"cell_id":"8e95b0c0ed5f4d918bab29a903db6c84","deepnote_cell_type":"markdown"},"source":"## Making Predictions\n\nLet's make some predictions using this model that we just created:","block_group":"c2e7c2b661cd48debc2f8b9235d4a648"},{"cell_type":"code","metadata":{"source_hash":"4bda912d","execution_start":1763839693402,"execution_millis":1,"execution_context_id":"257866fe-2a6e-4b56-87d9-82b66555a8a2","cell_id":"9d2710f3616348eaab483719bfcb9a3a","deepnote_cell_type":"code"},"source":"# make predictions using .predict()\n# notice how we use X_test here\n\npredictions = model.predict(X_test)\nprint(predictions)  # Predicted labels for the test data","block_group":"9499707b0b8e469981e846c028907b6d","execution_count":24,"outputs":[{"name":"stdout","text":"[2 0 2 2 2 0 1 2 2 1 2 0 0 0 0 2 2 2 2 2 0 2 0 2 2 2 2 2 0 0]\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/d135c699-82c7-4ee1-8035-012dcd526e4e","content_dependencies":null},{"cell_type":"markdown","metadata":{"cell_id":"6a1aa7e8b26f4435b3ca3adb09397f60","deepnote_cell_type":"markdown"},"source":"## Evaluating the Model\n\nWe've created a model and made some predictions for the X_test data!\nBUT how well did this model do?\n\nLet's find the accuracy:","block_group":"de2a4f4666fd4f3297eca350183097be"},{"cell_type":"code","metadata":{"source_hash":"98cd27d6","execution_start":1763839693452,"execution_millis":1,"execution_context_id":"257866fe-2a6e-4b56-87d9-82b66555a8a2","cell_id":"8623568f62684a13981dc77c0d061c7c","deepnote_cell_type":"code"},"source":"from sklearn.metrics import accuracy_score # import accuracy_score function\n\n# calculate the accuracy\naccuracy = accuracy_score(y_test, predictions)\nprint(f\"Accuracy: {accuracy * 100:.2f}%\")","block_group":"094e257932c3473997a84edf437c1e7a","execution_count":25,"outputs":[{"name":"stdout","text":"Accuracy: 76.67%\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/b7d46020-247b-47d9-b102-34c2200cf209","content_dependencies":null},{"cell_type":"markdown","metadata":{"cell_id":"4432ec7cd15c4cd79683143e8b1c0f2f","deepnote_cell_type":"markdown"},"source":"## Changing the Model (an iterative process)\n\nOk, so an accuracy of 77% is not bad, but remember when I said setting max_iter to 5 is too low?\nSo let's try changing that number to 100:","block_group":"b9d4fd91745b421592cb34ee2a48bf89"},{"cell_type":"code","metadata":{"source_hash":"dde1e5d6","execution_start":1763839693512,"execution_millis":1,"execution_context_id":"257866fe-2a6e-4b56-87d9-82b66555a8a2","cell_id":"9dbdb9ee1fac48a4a208c85a19f74790","deepnote_cell_type":"code"},"source":"model2 = LogisticRegression(max_iter=100) # new max_iter of 100\n\n# train the model\nmodel2.fit(X_train, y_train)\n\n# make predictions\npredictions2 = model2.predict(X_test) # (you don't need to use different variable names here)\n\n# calculate accuracy\naccuracy2 = accuracy_score(y_test, predictions2)\nprint(f\"Accuracy: {accuracy2 * 100:.2f}%\")","block_group":"53dbb72fcb6e4d28bb239d5679294d65","execution_count":26,"outputs":[{"name":"stdout","text":"Accuracy: 100.00%\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/4a05580f-11ef-43ea-911d-b7b31fb785d1","content_dependencies":null},{"cell_type":"markdown","metadata":{"cell_id":"8ff1934d60644e139e5d15b2ef65de0e","deepnote_cell_type":"markdown"},"source":"WOW!\n\nNote that in the real world, accuracies of 100% are usually unseen, but since this is such a simple dataset with a clear pattern, we've achieved 100% accuracy!","block_group":"76f5f47b14bf4654a76bd67a95d5e077"},{"cell_type":"markdown","metadata":{"cell_id":"224327b18c41442cbd583b4a6e24f1c0","deepnote_cell_type":"markdown"},"source":"## For fun: Plotting Data\n\nStudents: take a look at this section if you'd like to see how we can now plot this data!","block_group":"977db56186904127a59aaddea14544e5"},{"cell_type":"code","metadata":{"source_hash":"b35ab473","execution_start":1763840016054,"execution_millis":9,"execution_context_id":"257866fe-2a6e-4b56-87d9-82b66555a8a2","cell_id":"336ae615170645e39a426b4ad0e59a87","deepnote_cell_type":"code"},"source":"import matplotlib.pyplot as plt\nimport numpy as np\n\n# Fixing the error by ensuring matplotlib is correctly configured\n# The error might be due to a corrupted matplotlib configuration file.\n# Resetting the matplotlib configuration can help.\n\n# Resetting matplotlib configuration\nplt.rcParams.update(plt.rcParamsDefault)\n\n# plt.scatter(X[:, 0], X[:, 1], c=y, cmap='viridis', edgecolor='k', s=50)\n# plt.xlabel('Sepal Length')\n# plt.ylabel('Sepal Width')\n# plt.title('Iris Dataset: Sepal Length vs Width')\n# plt.colorbar(ticks=[0, 1, 2], label='Species')\n# plt.show()","block_group":"7eacd5832fee4b818017d407ddd506d5","execution_count":69,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"cell_id":"88abccd02438499c92d390ae7c99c5f1","deepnote_cell_type":"markdown"},"source":"## Exercises\n\n### Pandas\n\nWe've covered a a lot of information, but let's practice _how_ to find more information on pandas:\nLook for more functions that could be useful in the pandas documentation at this link: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html\n\n##### Exercise 1:\nFind a few functions that could be uesful and tell us what they do.\n\n#### And now, practice using the pandas library with these next exercises:\n\n##### Exercise 2: \nCreate a DataFrame of your own with made-up data on a topic of interest (e.g., favorite movies, sports stats).\n##### Exercise 3: \nFilter rows based on a specific condition (like a rating of 4 stars or higher).\n##### Exercise 4: \nAdd a new column based on existing data (e.g., a “Recommended” column for movies rated 4 stars or more).\n\n##### Exercise 5:\nTry plotting data from your DataFrame (e.g., using matplotlib from last week!).\n\n##### (Longer) Exercise 6:\nFind a cool dataset from kaggle (or anywhere else), perform some basic data analysis with pandas, and present your findings!","block_group":"514d9642c3d644959b00cf69b48e83b0"},{"cell_type":"code","metadata":{"source_hash":"ace1da82","execution_start":1763839930092,"execution_millis":0,"execution_context_id":"257866fe-2a6e-4b56-87d9-82b66555a8a2","cell_id":"33dd0d7c8ef448519ad21c3075210ca3","deepnote_cell_type":"code"},"source":"#for exercise\n","block_group":"89bbf5b3802e407a9b53dcafd51c58c7","execution_count":48,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"cell_id":"b395516c87b04200982638f70d3c746c","deepnote_cell_type":"markdown"},"source":"### Sklearn\n\nLook for different types of models that sklearn has built-in at this link: https://scikit-learn.org/stable/supervised_learning.html\n(We'll be getting into some of these in the coming weeks!)\n\n##### Exercise 7:\nInput your own hypothetical flower data into model2 and see what it predicts! \nFor example, execute these commands: \n`new_flower = [[val_1, val_2, val_3, val_4]]`\n`prediction_for_new_flower = model2.predict(new_flower)`\n`print(\"The model predicts that new_flower is of species: \", prediction_for_new_flower[0])`\n\n##### (Longer) Exercise 8: \nPredict Housing Prices using the boston housing dataset.\nLoad the dataset with the following code: `from sklearn.datasets import load_boston`\nHere is a layout of the steps you should follow:\n\n1. Load the dataset\n2. Split it into training and test sets (experiment with different split sizes)\n3. Use a **linear regression** model to predict the target value (home prices). (`from sklearn.linear_model import LinearRegression`)\n4. Calculate the model’s error using mean_squared_error. (`from sklearn.metrics import mean_squared_error`)\n5. Print a few predictions and compare them to actual values.\n6. Challenge: experiment with more features or remove features to see if the model performs better or worse\nYou can remove features using the drop() function: `X_reduced = X.drop(columns=['col_1', 'col_2', ..., 'col_n'])` - you can have as many or as little as you want!\nAnd when splitting the data, make sure the first parameter to `train_test_split` is `X_reduced`!","block_group":"54c68a1ef1ea4ab2b3c0d74126abb85e"},{"cell_type":"code","metadata":{"source_hash":"34dfaacd","execution_start":1763839798053,"execution_millis":985,"execution_context_id":"257866fe-2a6e-4b56-87d9-82b66555a8a2","cell_id":"138cc5062e2f497fa9dd767d0815853e","deepnote_cell_type":"code"},"source":"from sklearn.datasets import fetch_california_housing\n\nhousing = fetch_california_housing()\n\nX = housing.data\ny = housing.target\n\nprint(housing.DESCR)","block_group":"faffeac6cec44120b41fc74adeeecf56","execution_count":33,"outputs":[{"name":"stdout","text":".. _california_housing_dataset:\n\nCalifornia Housing dataset\n--------------------------\n\n**Data Set Characteristics:**\n\n    :Number of Instances: 20640\n\n    :Number of Attributes: 8 numeric, predictive attributes and the target\n\n    :Attribute Information:\n        - MedInc        median income in block group\n        - HouseAge      median house age in block group\n        - AveRooms      average number of rooms per household\n        - AveBedrms     average number of bedrooms per household\n        - Population    block group population\n        - AveOccup      average number of household members\n        - Latitude      block group latitude\n        - Longitude     block group longitude\n\n    :Missing Attribute Values: None\n\nThis dataset was obtained from the StatLib repository.\nhttps://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html\n\nThe target variable is the median house value for California districts,\nexpressed in hundreds of thousands of dollars ($100,000).\n\nThis dataset was derived from the 1990 U.S. census, using one row per census\nblock group. A block group is the smallest geographical unit for which the U.S.\nCensus Bureau publishes sample data (a block group typically has a population\nof 600 to 3,000 people).\n\nAn household is a group of people residing within a home. Since the average\nnumber of rooms and bedrooms in this dataset are provided per household, these\ncolumns may take surpinsingly large values for block groups with few households\nand many empty houses, such as vacation resorts.\n\nIt can be downloaded/loaded using the\n:func:`sklearn.datasets.fetch_california_housing` function.\n\n.. topic:: References\n\n    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\n      Statistics and Probability Letters, 33 (1997) 291-297\n\n","output_type":"stream"}],"outputs_reference":"s3:deepnote-cell-outputs-production/8ca3574f-605a-4fd8-80f0-0c73467c8efe","content_dependencies":null},{"cell_type":"markdown","metadata":{"cell_id":"9e4ea7890a0145d39d79a48649ba3bd3","deepnote_cell_type":"markdown"},"source":"### You've reached the end! Great job today guys!\n#### And be prepared to present excercies 1, 6, and 8 (if time permits!)","block_group":"e8ad970a024a47ebbf28457383ff587e"},{"cell_type":"markdown","metadata":{"cell_id":"6bcc01646b7c4274be10096725013a83","deepnote_cell_type":"markdown"},"source":"## Feedback:\nPlease fill out this form - it would be absolutely amazing! \nhttps://forms.gle/nGfvLHbP76jQNyyA9","block_group":"ec1e9a2be3a2405f984876ac9e22f820"},{"cell_type":"markdown","metadata":{"cell_id":"9ade049caf024241b4174cde759debea","deepnote_cell_type":"markdown"},"source":"","block_group":"d3a02dd3d9c74ebb8515acdd6e7b838f"},{"cell_type":"code","metadata":{"source_hash":"c5f192ce","execution_start":1763839812302,"execution_millis":1,"execution_context_id":"257866fe-2a6e-4b56-87d9-82b66555a8a2","cell_id":"430f6090a6d7434184b543ac123a05c8","deepnote_cell_type":"code"},"source":"# Step 1: Import libraries\nimport numpy as np\nimport pandas as pd\nfrom sklearn.datasets import load_boston  \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\n\n# Step 2: Load the dataset\nboston = load_boston()\nX = pd.DataFrame(boston.data, columns=boston.feature_names)\ny = pd.Series(boston.target, name='PRICE')\n\n# Optional: View feature names\nprint(\"Features:\", list(X.columns))\n\n# Step 3: Feature selection (Challenge step)\n# Example: Remove 'INDUS' and 'AGE' to test performance\nX_reduced = X.drop(columns=['INDUS', 'AGE'])\n\n# Step 4: Split the data (experiment with different test sizes)\nX_train, X_test, y_train, y_test = train_test_split(X_reduced, y, test_size=0.2, random_state=42)\n\n# Step 5: Train the model\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n\n# Step 6: Make predictions\ny_pred = model.predict(X_test)\n\n# Step 7: Evaluate the model\nmse = mean_squared_error(y_test, y_pred)\nprint(f\"Mean Squared Error: {mse:.2f}\")\n\n# Step 8: Compare predictions to actual values\ncomparison_df = pd.DataFrame({'Actual': y_test.values, 'Predicted': y_pred})\nprint(comparison_df.head(10))  # Show first 10 comparisons\n","block_group":"17ec0ab8f930428f945856bf0bbab936","execution_count":36,"outputs":[{"name":"stdout","text":"Features: ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT']\nMean Squared Error: 24.09\n   Actual  Predicted\n0    23.6  29.290302\n1    32.4  35.892006\n2    13.6  14.680930\n3    22.8  24.634702\n4    16.1  18.770526\n5    20.0  23.229169\n6    17.8  17.746493\n7    14.0  14.099629\n8    19.6  22.992163\n9    16.8  20.783285\n/root/venv/lib/python3.10/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n\n    The Boston housing prices dataset has an ethical problem. You can refer to\n    the documentation of this function for further details.\n\n    The scikit-learn maintainers therefore strongly discourage the use of this\n    dataset unless the purpose of the code is to study and educate about\n    ethical issues in data science and machine learning.\n\n    In this special case, you can fetch the dataset from the original\n    source::\n\n        import pandas as pd\n        import numpy as np\n\n        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n        target = raw_df.values[1::2, 2]\n\n    Alternative datasets include the California housing dataset (i.e.\n    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n    dataset. You can load the datasets as follows::\n\n        from sklearn.datasets import fetch_california_housing\n        housing = fetch_california_housing()\n\n    for the California housing dataset and::\n\n        from sklearn.datasets import fetch_openml\n        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n\n    for the Ames housing dataset.\n  warnings.warn(msg, category=FutureWarning)\n","output_type":"stream"}],"outputs_reference":"s3:deepnote-cell-outputs-production/81739d3a-e99e-4541-a187-7ef92cca1913","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"2d94e2dd","execution_start":1763839878092,"execution_millis":286,"execution_context_id":"257866fe-2a6e-4b56-87d9-82b66555a8a2","cell_id":"ce5c9a09478f42368c9eed9ed2eba8ed","deepnote_cell_type":"code"},"source":"new_df = pd.read_csv('sp500_companies.csv')\nprint(new_df)\n","block_group":"fe8c8afd63f64f7495ae140df75f886a","execution_count":42,"outputs":[{"name":"stdout","text":"    Exchange Symbol                    Shortname                     Longname  \\\n0        NMS   AAPL                   Apple Inc.                   Apple Inc.   \n1        NMS   NVDA           NVIDIA Corporation           NVIDIA Corporation   \n2        NMS   MSFT        Microsoft Corporation        Microsoft Corporation   \n3        NMS   AMZN             Amazon.com, Inc.             Amazon.com, Inc.   \n4        NMS  GOOGL                Alphabet Inc.                Alphabet Inc.   \n..       ...    ...                          ...                          ...   \n497      NMS    CZR  Caesars Entertainment, Inc.  Caesars Entertainment, Inc.   \n498      NYQ    BWA              BorgWarner Inc.              BorgWarner Inc.   \n499      NMS   QRVO                  Qorvo, Inc.                  Qorvo, Inc.   \n500      NYQ    FMC              FMC Corporation              FMC Corporation   \n501      NYQ   AMTM       Amentum Holdings, Inc.       Amentum Holdings, Inc.   \n\n                     Sector                        Industry  Currentprice  \\\n0                Technology            Consumer Electronics        254.49   \n1                Technology                  Semiconductors        134.70   \n2                Technology       Software - Infrastructure        436.60   \n3         Consumer Cyclical                 Internet Retail        224.92   \n4    Communication Services  Internet Content & Information        191.41   \n..                      ...                             ...           ...   \n497       Consumer Cyclical               Resorts & Casinos         32.82   \n498       Consumer Cyclical                      Auto Parts         31.88   \n499              Technology                  Semiconductors         70.85   \n500         Basic Materials             Agricultural Inputs         50.15   \n501             Industrials     Specialty Business Services         19.17   \n\n         Marketcap        Ebitda  Revenuegrowth           City State  \\\n0    3846819807232  1.346610e+11          0.061      Cupertino    CA   \n1    3298803056640  6.118400e+10          1.224    Santa Clara    CA   \n2    3246068596736  1.365520e+11          0.160        Redmond    WA   \n3    2365033807872  1.115830e+11          0.110        Seattle    WA   \n4    2351625142272  1.234700e+11          0.151  Mountain View    CA   \n..             ...           ...            ...            ...   ...   \n497     6973593600  3.668000e+09         -0.040           Reno    NV   \n498     6972155904  1.882000e+09         -0.048   Auburn Hills    MI   \n499     6697217024  6.731300e+08         -0.052     Greensboro    NC   \n500     6260525568  7.033000e+08          0.085   Philadelphia    PA   \n501     4664099328  4.330000e+08         -0.031      Chantilly    VA   \n\n           Country  Fulltimeemployees  \\\n0    United States           164000.0   \n1    United States            29600.0   \n2    United States           228000.0   \n3    United States          1551000.0   \n4    United States           181269.0   \n..             ...                ...   \n497  United States            51000.0   \n498  United States            39900.0   \n499  United States             8700.0   \n500  United States             5800.0   \n501  United States                NaN   \n\n                                   Longbusinesssummary    Weight  \n0    Apple Inc. designs, manufactures, and markets ...  0.069209  \n1    NVIDIA Corporation provides graphics and compu...  0.059350  \n2    Microsoft Corporation develops and supports so...  0.058401  \n3    Amazon.com, Inc. engages in the retail sale of...  0.042550  \n4    Alphabet Inc. offers various products and plat...  0.042309  \n..                                                 ...       ...  \n497  Caesars Entertainment, Inc. operates as a gami...  0.000125  \n498  BorgWarner Inc., together with its subsidiarie...  0.000125  \n499  Qorvo, Inc. engages in development and commerc...  0.000120  \n500  FMC Corporation, an agricultural sciences comp...  0.000113  \n501  Amentum Holdings, Inc. provides engineering an...  0.000084  \n\n[502 rows x 16 columns]\n","output_type":"stream"}],"outputs_reference":"s3:deepnote-cell-outputs-production/c7b5e84b-1d30-47a7-a3ee-62e5c9c23936","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"e0f30520","execution_start":1763839890049,"execution_millis":21,"execution_context_id":"257866fe-2a6e-4b56-87d9-82b66555a8a2","cell_id":"bfee6145347f4245b991290140c8091d","deepnote_cell_type":"code"},"source":"# Step 1: Import libraries\nimport numpy as np\nimport pandas as pd\nfrom sklearn.datasets import load_boston  # Deprecated in newer versions\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\n\n# Step 2: Load the dataset\nboston = load_boston()\nX = pd.DataFrame(boston.data, columns=boston.feature_names)\ny = pd.Series(boston.target, name='PRICE')\n\n# Optional: View feature names\nprint(\"Features:\", list(X.columns))\n\n# Step 3: Feature selection (Challenge step)\n# Example: Remove 'INDUS' and 'AGE' to test performance\nX_reduced = X.drop(columns=['INDUS', 'AGE'])\n\n# Step 4: Split the data (experiment with different test sizes)\nX_train, X_test, y_train, y_test = train_test_split(X_reduced, y, test_size=0.2, random_state=42)\n\n# Step 5: Train the model\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n\n# Step 6: Make predictions\ny_pred = model.predict(X_test)\n\n# Step 7: Evaluate the model\nmse = mean_squared_error(y_test, y_pred)\nprint(f\"Mean Squared Error: {mse:.2f}\")\n\n# Step 8: Compare predictions to actual values\ncomparison_df = pd.DataFrame({'Actual': y_test.values, 'Predicted': y_pred})\nprint(comparison_df.head(10))  # Show first 10 comparisons\n","block_group":"6041d113da7b440481e0793620905843","execution_count":45,"outputs":[{"name":"stdout","text":"Features: ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT']\nMean Squared Error: 24.09\n   Actual  Predicted\n0    23.6  29.290302\n1    32.4  35.892006\n2    13.6  14.680930\n3    22.8  24.634702\n4    16.1  18.770526\n5    20.0  23.229169\n6    17.8  17.746493\n7    14.0  14.099629\n8    19.6  22.992163\n9    16.8  20.783285\n/root/venv/lib/python3.10/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n\n    The Boston housing prices dataset has an ethical problem. You can refer to\n    the documentation of this function for further details.\n\n    The scikit-learn maintainers therefore strongly discourage the use of this\n    dataset unless the purpose of the code is to study and educate about\n    ethical issues in data science and machine learning.\n\n    In this special case, you can fetch the dataset from the original\n    source::\n\n        import pandas as pd\n        import numpy as np\n\n        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n        target = raw_df.values[1::2, 2]\n\n    Alternative datasets include the California housing dataset (i.e.\n    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n    dataset. You can load the datasets as follows::\n\n        from sklearn.datasets import fetch_california_housing\n        housing = fetch_california_housing()\n\n    for the California housing dataset and::\n\n        from sklearn.datasets import fetch_openml\n        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n\n    for the Ames housing dataset.\n  warnings.warn(msg, category=FutureWarning)\n","output_type":"stream"}],"outputs_reference":"s3:deepnote-cell-outputs-production/788ee126-e96e-42df-8466-3a985a66f6b7","content_dependencies":null},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=86be194c-a58f-44be-865a-f3ff49e932e3' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"deepnote_persisted_session":{"createdAt":"2025-10-26T18:22:09.950Z"},"deepnote_notebook_id":"f12386ca027f467db3e3a26a575f0253"}}